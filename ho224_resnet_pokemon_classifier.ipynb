{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG5-tdCMZJ1s"
      },
      "outputs": [],
      "source": [
        "# CELL 1 (do not change)\n",
        "\"\"\"import statements and boiler plate code\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow import Tensor\n",
        "from tensorflow.keras.layers import Input, ReLU, LeakyReLU, Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization, AveragePooling2D, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from keras import layers\n",
        "from PIL import Image\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# CELL 2 preprocessing\n",
        "'''\n",
        "to the pipeline:\n",
        "    - add a random flip\n",
        "    - random hue, max alpha = 0.3\n",
        "    - random brightness, max alpha = 0.3\n",
        "    - random_contrast, min = 0.9, max = 1.1\n",
        "'''\n",
        "##Setting an environmental variable so that CUDA doesn't run out of memory\n",
        "#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:100'\n",
        "\n",
        "\"\"\"script to load data set and print info\"\"\"\n",
        "with open('pokemon.pkl', 'rb') as f:\n",
        "  df = pickle.load(f)                 # dataset dataframe\n",
        "target = df.pop('Type1')\n",
        "\n",
        "target = list(target)\n",
        "\n",
        "#Counting how many images there are in the dataframe\n",
        "number_images = len(df.axes[0])\n",
        "#Initializing an empty numpy array for the images\n",
        "img_array = np.empty(shape = (number_images, 120, 120, 3))\n",
        "#Initializing a count variable\n",
        "i = 0\n",
        "\n",
        "for element in df['ImagePath']:\n",
        "  element = element.replace(\"/content/workshop-f22/pokemon-dataset/\", '')\n",
        "\n",
        "  #Convering the image into an RGB image first through PIL Image\n",
        "  image = Image.open(element)\n",
        "  image = image.convert('RGB')\n",
        "  image = np.array(image)\n",
        "  image = image.reshape((1, 120, 120, 3))\n",
        "\n",
        "  # print(\"Shape of the loaded image: \" +str(image.shape))\n",
        "\n",
        "  #Attributing values in the empty array into the values from image\n",
        "  img_array[i] = image\n",
        "  i += 1\n",
        "\n",
        "print(img_array.shape)\n",
        "\n",
        "\n",
        "#Implementing One Hot Encoding\n",
        "categories = np.array(list(set(target)))\n",
        "n_categories = len(categories)\n",
        "ohe_labels = np.zeros((len(target), n_categories))\n",
        "for ii in range(len(target)):\n",
        "  jj = np.where(categories == target[ii])\n",
        "  ohe_labels[ii][jj] = 1\n",
        "\n",
        "\n",
        "#Defining the Relu & Batch Normalization Pipeline\n",
        "def relu_bn(inputs: Tensor) -> Tensor:\n",
        "    relu = ReLU()(inputs)\n",
        "    bn = BatchNormalization()(relu)\n",
        "    return bn\n",
        "\n",
        "#Defining the Residual block (can be changed later on)\n",
        "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
        "    y = Conv2D(kernel_size = kernel_size,\n",
        "               strides = (1 if not downsample else 2),\n",
        "               filters = filters,\n",
        "               padding = \"same\")(x)\n",
        "    y = relu_bn(y)\n",
        "    y = Conv2D(kernel_size = kernel_size,\n",
        "               strides = 1,\n",
        "               filters = filters,\n",
        "               padding = \"same\")(y)\n",
        "    if downsample:\n",
        "        x = Conv2D(kernel_size = 1, strides = 2, filters = filters, padding = \"same\")(x)\n",
        "    out = Add()([x, y])\n",
        "    out = relu_bn(out)\n",
        "    return out\n",
        "\n",
        "def create_res_net():\n",
        "\n",
        "    inputs = Input(shape = (img_array.shape[1], img_array.shape[2], 3))\n",
        "    #Subject to change\n",
        "    num_filters = 64\n",
        "    t = layers.RandomFlip(\"horizontal_and_vertical\")(inputs)\n",
        "    t = layers.RandomContrast(0.9, 1.1)(t)\n",
        "    t = tf.keras.layers.RandomBrightness([-1, 0.3])(t)\n",
        "    t = Conv2D(kernel_size = 3,\n",
        "               strides = 1,\n",
        "               filters = num_filters,\n",
        "               padding = \"same\")(t)\n",
        "    t = relu_bn(t)\n",
        "\n",
        "    #Subject to change\n",
        "    num_blocks_list  = [2, 5, 5, 2]\n",
        "    for i in range(len(num_blocks_list)):\n",
        "        num_blocks = num_blocks_list[i]\n",
        "        for j in range(num_blocks):\n",
        "            t = residual_block(t, downsample = (j==0 and i!=0), filters = num_filters)\n",
        "        num_filters *= 2\n",
        "\n",
        "    #Subject to change\n",
        "    t = AveragePooling2D(2)(t)\n",
        "    t = Flatten()(t)\n",
        "    outputs = Dense(len(categories), activation = 'softmax')(t)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer = 'adam',\n",
        "        loss = 'categorical_crossentropy',\n",
        "        metrics = ['accuracy']\n",
        "        )\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "#Creating the model\n",
        "model = create_res_net()\n",
        "model.summary()      \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model\n",
        "model.fit(\n",
        "    x = img_array,\n",
        "    y = ohe_labels,\n",
        "    epochs = 38,\n",
        "    verbose = 1,\n",
        "    validation_split = 0.2,\n",
        "    batch_size = 128,\n",
        "    )"
      ],
      "metadata": {
        "id": "2vHyvqyhZP5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}